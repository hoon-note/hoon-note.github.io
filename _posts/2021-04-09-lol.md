---
layout: single
title: 'Python ML 연습문제(롤 승리요소 분석하기)'
---


#  리그 오브 레전드의 승리 요소 분석해보기

----------


## 데이터 소개

    - 각 파일의 컬럼은 아래와 같습니다.
    gameId: 게임 판의 고유 ID
    blueWins: 블루팀의 승리 여부 (0: 패배, 1: 승리)
    xxxWardsPlaced: xxx팀에서 설치한 와드의 수 
    xxxWardsDestroyed: xxx팀에서 파괴한 와드의 수
    xxxFirstBlood: xxx팀의 첫번째 킬 달성 여부
    xxxKills: xxx팀의 킬 수
    xxxDeaths: xxx팀의 죽음 수
    xxxAssists: xxx팀의 어시스트 수
    xxxEliteMonsters: xxx팀이 죽인 엘리트 몬스터 수
    xxxDragons: xxx팀이 죽인 용의 수
    xxxHeralds: xxx팀이 죽인 전령의 수
    xxxTowersDestroyed: xxx팀이 파괴한 탑의 수
    xxxTotalGold: xxx팀의 전체 획득 골드
    xxxAvgLevel: xxx팀의 평균 레벨
    xxxTotalExperience: xxx팀의 총 경험치 획득량
    xxxTotalMinionsKilled: xxx팀의 총 미니언 킬 수
    xxxTotalJungleMinionsKilled: xxx팀의 총 정글 미니언 킬 수
    xxxGoldDiff: xxx팀과 다른 팀 간의 골드 획득량 차이
    xxxExperienceDiff: xxx팀과 다른 팀과의 경험치 획득량 차이
    xxxCSPerMin: xxx팀의 분당 CS 스코어
    xxxGoldPerMin: xxx팀의 분당 골드 획득량


​    
​    

- 데이터 출처: https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min

---

## Step 1. 데이터셋 준비하기


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```


```python
# pd.read_csv()로 csv파일 읽어들이기
df = pd.read_csv('high_diamond_ranked_10min.csv')
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gameId</th>
      <th>blueWins</th>
      <th>blueWardsPlaced</th>
      <th>blueWardsDestroyed</th>
      <th>blueFirstBlood</th>
      <th>blueKills</th>
      <th>blueDeaths</th>
      <th>blueAssists</th>
      <th>blueEliteMonsters</th>
      <th>blueDragons</th>
      <th>blueHeralds</th>
      <th>blueTowersDestroyed</th>
      <th>blueTotalGold</th>
      <th>blueAvgLevel</th>
      <th>blueTotalExperience</th>
      <th>blueTotalMinionsKilled</th>
      <th>blueTotalJungleMinionsKilled</th>
      <th>blueGoldDiff</th>
      <th>blueExperienceDiff</th>
      <th>blueCSPerMin</th>
      <th>blueGoldPerMin</th>
      <th>redWardsPlaced</th>
      <th>redWardsDestroyed</th>
      <th>redFirstBlood</th>
      <th>redKills</th>
      <th>redDeaths</th>
      <th>redAssists</th>
      <th>redEliteMonsters</th>
      <th>redDragons</th>
      <th>redHeralds</th>
      <th>redTowersDestroyed</th>
      <th>redTotalGold</th>
      <th>redAvgLevel</th>
      <th>redTotalExperience</th>
      <th>redTotalMinionsKilled</th>
      <th>redTotalJungleMinionsKilled</th>
      <th>redGoldDiff</th>
      <th>redExperienceDiff</th>
      <th>redCSPerMin</th>
      <th>redGoldPerMin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4519157822</td>
      <td>0</td>
      <td>28</td>
      <td>2</td>
      <td>1</td>
      <td>9</td>
      <td>6</td>
      <td>11</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>17210</td>
      <td>6.6</td>
      <td>17039</td>
      <td>195</td>
      <td>36</td>
      <td>643</td>
      <td>-8</td>
      <td>19.5</td>
      <td>1721.0</td>
      <td>15</td>
      <td>6</td>
      <td>0</td>
      <td>6</td>
      <td>9</td>
      <td>8</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>16567</td>
      <td>6.8</td>
      <td>17047</td>
      <td>197</td>
      <td>55</td>
      <td>-643</td>
      <td>8</td>
      <td>19.7</td>
      <td>1656.7</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4523371949</td>
      <td>0</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>14712</td>
      <td>6.6</td>
      <td>16265</td>
      <td>174</td>
      <td>43</td>
      <td>-2908</td>
      <td>-1173</td>
      <td>17.4</td>
      <td>1471.2</td>
      <td>12</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>5</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>17620</td>
      <td>6.8</td>
      <td>17438</td>
      <td>240</td>
      <td>52</td>
      <td>2908</td>
      <td>1173</td>
      <td>24.0</td>
      <td>1762.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4521474530</td>
      <td>0</td>
      <td>15</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>11</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>16113</td>
      <td>6.4</td>
      <td>16221</td>
      <td>186</td>
      <td>46</td>
      <td>-1172</td>
      <td>-1033</td>
      <td>18.6</td>
      <td>1611.3</td>
      <td>15</td>
      <td>3</td>
      <td>1</td>
      <td>11</td>
      <td>7</td>
      <td>14</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>17285</td>
      <td>6.8</td>
      <td>17254</td>
      <td>203</td>
      <td>28</td>
      <td>1172</td>
      <td>1033</td>
      <td>20.3</td>
      <td>1728.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4524384067</td>
      <td>0</td>
      <td>43</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>15157</td>
      <td>7.0</td>
      <td>17954</td>
      <td>201</td>
      <td>55</td>
      <td>-1321</td>
      <td>-7</td>
      <td>20.1</td>
      <td>1515.7</td>
      <td>15</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>4</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>16478</td>
      <td>7.0</td>
      <td>17961</td>
      <td>235</td>
      <td>47</td>
      <td>1321</td>
      <td>7</td>
      <td>23.5</td>
      <td>1647.8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4436033771</td>
      <td>0</td>
      <td>75</td>
      <td>4</td>
      <td>0</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>16400</td>
      <td>7.0</td>
      <td>18543</td>
      <td>210</td>
      <td>57</td>
      <td>-1004</td>
      <td>230</td>
      <td>21.0</td>
      <td>1640.0</td>
      <td>17</td>
      <td>2</td>
      <td>1</td>
      <td>6</td>
      <td>6</td>
      <td>7</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>17404</td>
      <td>7.0</td>
      <td>18313</td>
      <td>225</td>
      <td>67</td>
      <td>1004</td>
      <td>-230</td>
      <td>22.5</td>
      <td>1740.4</td>
    </tr>
  </tbody>
</table>

</div>



## Step 2. EDA 및 데이터 기초 통계 분석


### 데이터프레임의 각 컬럼 분석하기



```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 9879 entries, 0 to 9878
    Data columns (total 40 columns):
     #   Column                        Non-Null Count  Dtype  
    ---  ------                        --------------  -----  
     0   gameId                        9879 non-null   int64  
     1   blueWins                      9879 non-null   int64  
     2   blueWardsPlaced               9879 non-null   int64  
     3   blueWardsDestroyed            9879 non-null   int64  
     4   blueFirstBlood                9879 non-null   int64  
     5   blueKills                     9879 non-null   int64  
     6   blueDeaths                    9879 non-null   int64  
     7   blueAssists                   9879 non-null   int64  
     8   blueEliteMonsters             9879 non-null   int64  
     9   blueDragons                   9879 non-null   int64  
     10  blueHeralds                   9879 non-null   int64  
     11  blueTowersDestroyed           9879 non-null   int64  
     12  blueTotalGold                 9879 non-null   int64  
     13  blueAvgLevel                  9879 non-null   float64
     14  blueTotalExperience           9879 non-null   int64  
     15  blueTotalMinionsKilled        9879 non-null   int64  
     16  blueTotalJungleMinionsKilled  9879 non-null   int64  
     17  blueGoldDiff                  9879 non-null   int64  
     18  blueExperienceDiff            9879 non-null   int64  
     19  blueCSPerMin                  9879 non-null   float64
     20  blueGoldPerMin                9879 non-null   float64
     21  redWardsPlaced                9879 non-null   int64  
     22  redWardsDestroyed             9879 non-null   int64  
     23  redFirstBlood                 9879 non-null   int64  
     24  redKills                      9879 non-null   int64  
     25  redDeaths                     9879 non-null   int64  
     26  redAssists                    9879 non-null   int64  
     27  redEliteMonsters              9879 non-null   int64  
     28  redDragons                    9879 non-null   int64  
     29  redHeralds                    9879 non-null   int64  
     30  redTowersDestroyed            9879 non-null   int64  
     31  redTotalGold                  9879 non-null   int64  
     32  redAvgLevel                   9879 non-null   float64
     33  redTotalExperience            9879 non-null   int64  
     34  redTotalMinionsKilled         9879 non-null   int64  
     35  redTotalJungleMinionsKilled   9879 non-null   int64  
     36  redGoldDiff                   9879 non-null   int64  
     37  redExperienceDiff             9879 non-null   int64  
     38  redCSPerMin                   9879 non-null   float64
     39  redGoldPerMin                 9879 non-null   float64
    dtypes: float64(6), int64(34)
    memory usage: 3.0 MB



```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gameId</th>
      <th>blueWins</th>
      <th>blueWardsPlaced</th>
      <th>blueWardsDestroyed</th>
      <th>blueFirstBlood</th>
      <th>blueKills</th>
      <th>blueDeaths</th>
      <th>blueAssists</th>
      <th>blueEliteMonsters</th>
      <th>blueDragons</th>
      <th>blueHeralds</th>
      <th>blueTowersDestroyed</th>
      <th>blueTotalGold</th>
      <th>blueAvgLevel</th>
      <th>blueTotalExperience</th>
      <th>blueTotalMinionsKilled</th>
      <th>blueTotalJungleMinionsKilled</th>
      <th>blueGoldDiff</th>
      <th>blueExperienceDiff</th>
      <th>blueCSPerMin</th>
      <th>blueGoldPerMin</th>
      <th>redWardsPlaced</th>
      <th>redWardsDestroyed</th>
      <th>redFirstBlood</th>
      <th>redKills</th>
      <th>redDeaths</th>
      <th>redAssists</th>
      <th>redEliteMonsters</th>
      <th>redDragons</th>
      <th>redHeralds</th>
      <th>redTowersDestroyed</th>
      <th>redTotalGold</th>
      <th>redAvgLevel</th>
      <th>redTotalExperience</th>
      <th>redTotalMinionsKilled</th>
      <th>redTotalJungleMinionsKilled</th>
      <th>redGoldDiff</th>
      <th>redExperienceDiff</th>
      <th>redCSPerMin</th>
      <th>redGoldPerMin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>9.879000e+03</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
      <td>9879.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>4.500084e+09</td>
      <td>0.499038</td>
      <td>22.288288</td>
      <td>2.824881</td>
      <td>0.504808</td>
      <td>6.183925</td>
      <td>6.137666</td>
      <td>6.645106</td>
      <td>0.549954</td>
      <td>0.361980</td>
      <td>0.187974</td>
      <td>0.051422</td>
      <td>16503.455512</td>
      <td>6.916004</td>
      <td>17928.110133</td>
      <td>216.699565</td>
      <td>50.509667</td>
      <td>14.414111</td>
      <td>-33.620306</td>
      <td>21.669956</td>
      <td>1650.345551</td>
      <td>22.367952</td>
      <td>2.723150</td>
      <td>0.495192</td>
      <td>6.137666</td>
      <td>6.183925</td>
      <td>6.662112</td>
      <td>0.573135</td>
      <td>0.413098</td>
      <td>0.160036</td>
      <td>0.043021</td>
      <td>16489.041401</td>
      <td>6.925316</td>
      <td>17961.730438</td>
      <td>217.349226</td>
      <td>51.313088</td>
      <td>-14.414111</td>
      <td>33.620306</td>
      <td>21.734923</td>
      <td>1648.904140</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.757328e+07</td>
      <td>0.500024</td>
      <td>18.019177</td>
      <td>2.174998</td>
      <td>0.500002</td>
      <td>3.011028</td>
      <td>2.933818</td>
      <td>4.064520</td>
      <td>0.625527</td>
      <td>0.480597</td>
      <td>0.390712</td>
      <td>0.244369</td>
      <td>1535.446636</td>
      <td>0.305146</td>
      <td>1200.523764</td>
      <td>21.858437</td>
      <td>9.898282</td>
      <td>2453.349179</td>
      <td>1920.370438</td>
      <td>2.185844</td>
      <td>153.544664</td>
      <td>18.457427</td>
      <td>2.138356</td>
      <td>0.500002</td>
      <td>2.933818</td>
      <td>3.011028</td>
      <td>4.060612</td>
      <td>0.626482</td>
      <td>0.492415</td>
      <td>0.366658</td>
      <td>0.216900</td>
      <td>1490.888406</td>
      <td>0.305311</td>
      <td>1198.583912</td>
      <td>21.911668</td>
      <td>10.027885</td>
      <td>2453.349179</td>
      <td>1920.370438</td>
      <td>2.191167</td>
      <td>149.088841</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.295358e+09</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>10730.000000</td>
      <td>4.600000</td>
      <td>10098.000000</td>
      <td>90.000000</td>
      <td>0.000000</td>
      <td>-10830.000000</td>
      <td>-9333.000000</td>
      <td>9.000000</td>
      <td>1073.000000</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>11212.000000</td>
      <td>4.800000</td>
      <td>10465.000000</td>
      <td>107.000000</td>
      <td>4.000000</td>
      <td>-11467.000000</td>
      <td>-8348.000000</td>
      <td>10.700000</td>
      <td>1121.200000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.483301e+09</td>
      <td>0.000000</td>
      <td>14.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>15415.500000</td>
      <td>6.800000</td>
      <td>17168.000000</td>
      <td>202.000000</td>
      <td>44.000000</td>
      <td>-1585.500000</td>
      <td>-1290.500000</td>
      <td>20.200000</td>
      <td>1541.550000</td>
      <td>14.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>15427.500000</td>
      <td>6.800000</td>
      <td>17209.500000</td>
      <td>203.000000</td>
      <td>44.000000</td>
      <td>-1596.000000</td>
      <td>-1212.000000</td>
      <td>20.300000</td>
      <td>1542.750000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>4.510920e+09</td>
      <td>0.000000</td>
      <td>16.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>16398.000000</td>
      <td>7.000000</td>
      <td>17951.000000</td>
      <td>218.000000</td>
      <td>50.000000</td>
      <td>14.000000</td>
      <td>-28.000000</td>
      <td>21.800000</td>
      <td>1639.800000</td>
      <td>16.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>16378.000000</td>
      <td>7.000000</td>
      <td>17974.000000</td>
      <td>218.000000</td>
      <td>51.000000</td>
      <td>-14.000000</td>
      <td>28.000000</td>
      <td>21.800000</td>
      <td>1637.800000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.521733e+09</td>
      <td>1.000000</td>
      <td>20.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>8.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>17459.000000</td>
      <td>7.200000</td>
      <td>18724.000000</td>
      <td>232.000000</td>
      <td>56.000000</td>
      <td>1596.000000</td>
      <td>1212.000000</td>
      <td>23.200000</td>
      <td>1745.900000</td>
      <td>20.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>8.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>17418.500000</td>
      <td>7.200000</td>
      <td>18764.500000</td>
      <td>233.000000</td>
      <td>57.000000</td>
      <td>1585.500000</td>
      <td>1290.500000</td>
      <td>23.300000</td>
      <td>1741.850000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.527991e+09</td>
      <td>1.000000</td>
      <td>250.000000</td>
      <td>27.000000</td>
      <td>1.000000</td>
      <td>22.000000</td>
      <td>22.000000</td>
      <td>29.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>23701.000000</td>
      <td>8.000000</td>
      <td>22224.000000</td>
      <td>283.000000</td>
      <td>92.000000</td>
      <td>11467.000000</td>
      <td>8348.000000</td>
      <td>28.300000</td>
      <td>2370.100000</td>
      <td>276.000000</td>
      <td>24.000000</td>
      <td>1.000000</td>
      <td>22.000000</td>
      <td>22.000000</td>
      <td>28.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>22732.000000</td>
      <td>8.200000</td>
      <td>22269.000000</td>
      <td>289.000000</td>
      <td>92.000000</td>
      <td>10830.000000</td>
      <td>9333.000000</td>
      <td>28.900000</td>
      <td>2273.200000</td>
    </tr>
  </tbody>
</table>

</div>



###  각 컬럼의 Correlation 히트맵으로 시각화하기



```python
#  heatmap() 메소드를 이용하여시각화하기
fig = plt.figure(figsize=(6,8))
sns.heatmap(df.corr()[['blueWins']],annot=True)

# blueWins팀의 승리와 상관관계가 높은것들 보기
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a9a901d0>



![image-center](/assets/images/l1.png){: .align-center}




```python
df.columns
```




    Index(['gameId', 'blueWins', 'blueWardsPlaced', 'blueWardsDestroyed',
           'blueFirstBlood', 'blueKills', 'blueDeaths', 'blueAssists',
           'blueEliteMonsters', 'blueDragons', 'blueHeralds',
           'blueTowersDestroyed', 'blueTotalGold', 'blueAvgLevel',
           'blueTotalExperience', 'blueTotalMinionsKilled',
           'blueTotalJungleMinionsKilled', 'blueGoldDiff', 'blueExperienceDiff',
           'blueCSPerMin', 'blueGoldPerMin', 'redWardsPlaced', 'redWardsDestroyed',
           'redFirstBlood', 'redKills', 'redDeaths', 'redAssists',
           'redEliteMonsters', 'redDragons', 'redHeralds', 'redTowersDestroyed',
           'redTotalGold', 'redAvgLevel', 'redTotalExperience',
           'redTotalMinionsKilled', 'redTotalJungleMinionsKilled', 'redGoldDiff',
           'redExperienceDiff', 'redCSPerMin', 'redGoldPerMin'],
          dtype='object')



### 각 컬럼과 승리 여부의 관계 시각화하기



```python
sns.histplot(data=df,x='blueGoldDiff',hue='blueWins',palette='RdBu',kde=True)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a9c2e710>




![image-center](/assets/images/l2.png){: .align-center}



```python
sns.histplot(data=df,x='blueKills',hue='blueWins',palette='RdBu',kde=True,bins=8)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1aa355c18>




![image-center](/assets/images/l3.png){: .align-center}



```python
sns.jointplot(data=df,x='blueKills',y='blueGoldDiff',hue='blueWins')
```




    <seaborn.axisgrid.JointGrid at 0x7fc1aa113eb8>




![image-center](/assets/images/l4.png){: .align-center}



```python
sns.jointplot(data=df,x='blueExperienceDiff',y='blueGoldDiff',hue='blueWins')
# 경험치와 돈은 높은 상관관계를 예상할 수 있음 
```




    <seaborn.axisgrid.JointGrid at 0x7fc1aa790400>




![image-center](/assets/images/l5.png){: .align-center}


```python
# Seaborn의 countplot() 및 histplot()을 사용하여 각 컬럼과 승/패의 관계를 시각화

sns.countplot(data=df,x='blueFirstBlood',hue='blueWins',palette='RdBu')

 # 히트맵에서 높은 상관성을 보이는 컬럼을 가져와서 확인
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a8d17828>




![image-center](/assets/images/l6.png){: .align-center}


```python
sns.countplot(data=df,x='redFirstBlood',hue='blueWins',palette='RdBu')

# 레드팀의 첫번째 킬과 블루팀의 승리의 연관성
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a8c20f28>




![image-center](/assets/images/l7.png){: .align-center}


```python
sns.countplot(data=df,x='blueDragons',hue='blueWins',palette='RdBu')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a8d431d0>




![image-center](/assets/images/l8.png){: .align-center}


```python
sns.countplot(data=df,x='redDragons',hue='blueWins',palette='RdBu')
# 레드가 처리하는것과 블루가 처리하는것은 비대칭적
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7fc1a8cbef28>




![image-center](/assets/images/l9.png){: .align-center}


## Step 3. 모델 학습을 위한 데이터 전처리


###  StandardScaler를 이용해 수치형 데이터 표준화하기



```python
from sklearn.preprocessing import StandardScaler
```


```python
df.columns
```




    Index(['gameId', 'blueWins', 'blueWardsPlaced', 'blueWardsDestroyed',
           'blueFirstBlood', 'blueKills', 'blueDeaths', 'blueAssists',
           'blueEliteMonsters', 'blueDragons', 'blueHeralds',
           'blueTowersDestroyed', 'blueTotalGold', 'blueAvgLevel',
           'blueTotalExperience', 'blueTotalMinionsKilled',
           'blueTotalJungleMinionsKilled', 'blueGoldDiff', 'blueExperienceDiff',
           'blueCSPerMin', 'blueGoldPerMin', 'redWardsPlaced', 'redWardsDestroyed',
           'redFirstBlood', 'redKills', 'redDeaths', 'redAssists',
           'redEliteMonsters', 'redDragons', 'redHeralds', 'redTowersDestroyed',
           'redTotalGold', 'redAvgLevel', 'redTotalExperience',
           'redTotalMinionsKilled', 'redTotalJungleMinionsKilled', 'redGoldDiff',
           'redExperienceDiff', 'redCSPerMin', 'redGoldPerMin'],
          dtype='object')




```python
df.drop(['gameId', 'redFirstBlood', 'redKills', 'redDeaths',
       'redTotalGold', 'redTotalExperience', 'redGoldDiff',
       'redExperienceDiff'], axis=1, inplace=True)
```


```python
# StandardScaler를 이용해 수치형 데이터를 표준화하기
# Hint) Multicollinearity를 피하기 위해 불필요한 컬럼은 drop한다.

X_num = df[['blueWardsPlaced', 'blueWardsDestroyed', 
       'blueKills', 'blueDeaths', 'blueAssists', 'blueEliteMonsters',
       'blueTowersDestroyed', 'blueTotalGold',
       'blueAvgLevel', 'blueTotalExperience', 'blueTotalMinionsKilled',
       'blueTotalJungleMinionsKilled', 'blueGoldDiff', 'blueExperienceDiff',
       'blueCSPerMin', 'blueGoldPerMin', 'redWardsPlaced', 'redWardsDestroyed',
       'redAssists', 'redEliteMonsters', 'redTowersDestroyed', 'redAvgLevel', 'redTotalMinionsKilled',
       'redTotalJungleMinionsKilled', 'redCSPerMin', 'redGoldPerMin']]

X_cat = df[['blueFirstBlood', 'blueDragons', 'blueHeralds', 'redDragons', 'redHeralds']]

scaler = StandardScaler()
scaler.fit(X_num)
X_scaled = scaler.transform(X_num)
X_scaled = pd.DataFrame(X_scaled,index=X_num.index,columns=X_num.columns)

X = pd.concat([X_scaled,X_cat],axis=1)
y = df['blueWins']
```


```python
X.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>blueWardsPlaced</th>
      <th>blueWardsDestroyed</th>
      <th>blueKills</th>
      <th>blueDeaths</th>
      <th>blueAssists</th>
      <th>blueEliteMonsters</th>
      <th>blueTowersDestroyed</th>
      <th>blueTotalGold</th>
      <th>blueAvgLevel</th>
      <th>blueTotalExperience</th>
      <th>blueTotalMinionsKilled</th>
      <th>blueTotalJungleMinionsKilled</th>
      <th>blueGoldDiff</th>
      <th>blueExperienceDiff</th>
      <th>blueCSPerMin</th>
      <th>blueGoldPerMin</th>
      <th>redWardsPlaced</th>
      <th>redWardsDestroyed</th>
      <th>redAssists</th>
      <th>redEliteMonsters</th>
      <th>redTowersDestroyed</th>
      <th>redAvgLevel</th>
      <th>redTotalMinionsKilled</th>
      <th>redTotalJungleMinionsKilled</th>
      <th>redCSPerMin</th>
      <th>redGoldPerMin</th>
      <th>blueFirstBlood</th>
      <th>blueDragons</th>
      <th>blueHeralds</th>
      <th>redDragons</th>
      <th>redHeralds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.316996</td>
      <td>-0.379275</td>
      <td>0.935301</td>
      <td>-0.046926</td>
      <td>1.071495</td>
      <td>-0.879231</td>
      <td>-0.210439</td>
      <td>0.460179</td>
      <td>-1.035635</td>
      <td>-0.740639</td>
      <td>-0.992782</td>
      <td>-1.465951</td>
      <td>0.256228</td>
      <td>0.013342</td>
      <td>-0.992782</td>
      <td>0.460179</td>
      <td>-0.399207</td>
      <td>1.532493</td>
      <td>0.329496</td>
      <td>-0.914893</td>
      <td>-0.198353</td>
      <td>-0.410475</td>
      <td>-0.928741</td>
      <td>0.367685</td>
      <td>-0.928741</td>
      <td>0.052293</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.570992</td>
      <td>-0.839069</td>
      <td>-0.393216</td>
      <td>-0.387796</td>
      <td>-0.404768</td>
      <td>-0.879231</td>
      <td>-0.210439</td>
      <td>-1.166792</td>
      <td>-1.035635</td>
      <td>-1.385391</td>
      <td>-1.953558</td>
      <td>-0.758722</td>
      <td>-1.191254</td>
      <td>-0.593342</td>
      <td>-1.953558</td>
      <td>-1.166792</td>
      <td>-0.561751</td>
      <td>-0.805870</td>
      <td>-1.148188</td>
      <td>2.277700</td>
      <td>4.412301</td>
      <td>-0.410475</td>
      <td>1.033784</td>
      <td>0.068504</td>
      <td>1.033784</td>
      <td>0.758619</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.404494</td>
      <td>-1.298863</td>
      <td>0.271042</td>
      <td>1.657424</td>
      <td>-0.650812</td>
      <td>0.719503</td>
      <td>-0.210439</td>
      <td>-0.254307</td>
      <td>-1.691092</td>
      <td>-1.422043</td>
      <td>-1.404543</td>
      <td>-0.455624</td>
      <td>-0.483614</td>
      <td>-0.520436</td>
      <td>-1.404543</td>
      <td>-0.254307</td>
      <td>-0.399207</td>
      <td>0.129475</td>
      <td>1.807181</td>
      <td>-0.914893</td>
      <td>-0.198353</td>
      <td>-0.410475</td>
      <td>-0.654900</td>
      <td>-2.324944</td>
      <td>-0.654900</td>
      <td>0.533909</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.149484</td>
      <td>-0.839069</td>
      <td>-0.725346</td>
      <td>-0.387796</td>
      <td>-0.404768</td>
      <td>0.719503</td>
      <td>-0.210439</td>
      <td>-0.876959</td>
      <td>0.275280</td>
      <td>0.021567</td>
      <td>-0.718275</td>
      <td>0.453671</td>
      <td>-0.544350</td>
      <td>0.013863</td>
      <td>-0.718275</td>
      <td>-0.876959</td>
      <td>-0.399207</td>
      <td>-0.338198</td>
      <td>0.822058</td>
      <td>-0.914893</td>
      <td>-0.198353</td>
      <td>0.244627</td>
      <td>0.805583</td>
      <td>-0.430131</td>
      <td>0.805583</td>
      <td>-0.007406</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.925460</td>
      <td>0.540312</td>
      <td>-0.061087</td>
      <td>-0.046926</td>
      <td>-0.158724</td>
      <td>-0.879231</td>
      <td>-0.210439</td>
      <td>-0.067382</td>
      <td>0.275280</td>
      <td>0.512211</td>
      <td>-0.306513</td>
      <td>0.655736</td>
      <td>-0.415133</td>
      <td>0.137283</td>
      <td>-0.306513</td>
      <td>-0.067382</td>
      <td>-0.290844</td>
      <td>-0.338198</td>
      <td>0.083215</td>
      <td>0.681403</td>
      <td>-0.198353</td>
      <td>0.244627</td>
      <td>0.349182</td>
      <td>1.564408</td>
      <td>0.349182</td>
      <td>0.613731</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

</div>



###  학습데이터와 테스트데이터 분리하기



```python
from sklearn.model_selection import train_test_split
```


```python
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)
```


```python
len(X_train),len(X_test)
```




    (6915, 2964)



## Step 4. Classification 모델 학습하기


### Logistic Regression 모델 생성/학습하기



```python
from sklearn.linear_model import LogisticRegression
```


```python
# LogisticRegression 모델 생성/학습
model_lr = LogisticRegression()
model_lr.fit(X_train,y_train)
```




    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=100,
                       multi_class='auto', n_jobs=None, penalty='l2',
                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                       warm_start=False)



###  모델 학습 결과 평가하기


```python
from sklearn.metrics import classification_report
```


```python
# Predict를 수행하고 classification_report() 결과 출력하기
pred = model_lr.predict(X_test)
print(classification_report(pred,y_test))

```

                  precision    recall  f1-score   support
    
               0       0.75      0.74      0.74      1491
               1       0.74      0.75      0.74      1473
    
        accuracy                           0.74      2964
       macro avg       0.74      0.74      0.74      2964
    weighted avg       0.74      0.74      0.74      2964


​    

### XGBoost 모델 생성/학습하기



```python
from xgboost import XGBClassifier
```


```python
# XGBClassifier 모델 생성/학습
model_xgb = XGBClassifier()
model_xgb.fit(X_train,y_train)
```




    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                  colsample_bynode=1, colsample_bytree=1, gamma=0,
                  learning_rate=0.1, max_delta_step=0, max_depth=3,
                  min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
                  nthread=None, objective='binary:logistic', random_state=0,
                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                  silent=None, subsample=1, verbosity=1)



### 모델 학습 결과 평가하기



```python
# Predict를 수행하고 classification_report() 결과 출력하기
pred = model_xgb.predict(X_test)
print(classification_report(pred,y_test))
```

                  precision    recall  f1-score   support
    
               0       0.75      0.73      0.74      1492
               1       0.74      0.75      0.74      1472
    
        accuracy                           0.74      2964
       macro avg       0.74      0.74      0.74      2964
    weighted avg       0.74      0.74      0.74      2964


​    

## Step5 모델 학습 결과 심화 분석하기


### Logistic Regression 모델 계수로 상관성 파악하기


```python
# Logistic Regression 모델의 coef_ 속성을 plot하기
model_coef = pd.DataFrame(data=model_lr.coef_[0], index=X.columns, columns=['Model'])
model_coef.sort_values(by='Model',ascending=False,inplace=True)
plt.bar(model_coef.index,model_coef['Model'])
plt.xticks(rotation=90)
plt.show()
```


![image-center](/assets/images/l10.png){: .align-center}


### XGBoost 모델로 특징의 중요도 확인하기


```python
# XGBoost 모델의 feature_importances_ 속성을 plot하기
fig = plt.figure(figsize=(8,8))
plt.barh(X.columns,model_xgb.feature_importances_)

# 각 팀의 골드와 경험치 획득량이 승리에 주요 요소이고 다른요소들이 골드와 경험치 획득량에 연관이 있음
```




    <BarContainer object of 31 artists>




![image-center](/assets/images/l11.png){: .align-center}



